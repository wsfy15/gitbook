# 批处理任务

Deployment、StatefulSet 和 DaemonSet 这三种编排的对象主要是 在线业务，即 Long Running Task（长作业）。比如，Nginx、MySQL 等等。这些应用一旦运行起来，除非出错或者停止，它的容器进程会一直保持在 Running 状态。

但是，离线业务类作业，或者叫 Batch Job（计算业务），显然不满足这样的条件。这种业务在计算完成后就直接退出了，而此时如果依然用 Deployment 来管理这种业务的话，就会发现 Pod 会在计算结束后退出，然后被 Deployment Controller 不断地重启；而像“滚动更新”这样的编排功能，更无从谈起了。

Kubernetes 中针对这类作业，有一个专门的 API 对象：Job。

## Job

### 定义

```
apiVersion: batch/v1
kind: Job
metadata:
  name: pi
spec:
  template:
    spec:
      containers:
      - name: pi
        image: resouer/ubuntu-bc
        command: ["sh", "-c", "echo 'scale=10000; 4*a(1)' | bc -l "]
      restartPolicy: Never
  backoffLimit: 4
```

这个 Job 执行的计算任务是使用Linux 里的计数器 `bc` 计算 $π$的值。

> `bc -l`表示使用标准数学库，`scale=10000`是指定输出小数点后10000位， `a(1)`是调用数学库中的 arctangent 函数，计算 atan(1)。
>
> 因为 $tan(π/4) = 1$，所以$ atan(1) = π/4$，$ 4 * atan(1) = π$



### 运行

```
$ kubectl create -f job.yaml
job.batch/pi created
$ kubectl describe job pi
Name:           pi
Namespace:      default
Selector:       controller-uid=e8379db8-c974-4f95-a263-e19dd22517ff
Labels:         controller-uid=e8379db8-c974-4f95-a263-e19dd22517ff
                job-name=pi
Annotations:    <none>
Parallelism:    1
Completions:    1
Start Time:     Tue, 14 Jul 2020 01:29:37 +0000
Pods Statuses:  1 Running / 0 Succeeded / 0 Failed
Pod Template:
  Labels:  controller-uid=e8379db8-c974-4f95-a263-e19dd22517ff
           job-name=pi
  Containers:
   pi:
    Image:      resouer/ubuntu-bc
    Port:       <none>
    Host Port:  <none>
    Command:
      sh
      -c
      echo 'scale=10000; 4*a(1)' | bc -l
    Environment:  <none>
    Mounts:       <none>
  Volumes:        <none>
Events:
  Type    Reason            Age   From            Message
  ----    ------            ----  ----            -------
  Normal  SuccessfulCreate  23s   job-controller  Created pod: pi-5b7vl
  
$ kubectl get po
NAME       READY   STATUS    RESTARTS   AGE
pi-5b7vl   1/1     Running   0          54s
```

这个 Job 对象在创建后，它的 Pod 模板，被自动加上了一个 `controller-uid=< 一个随机字符串 >` 这样的 Label。而这个 Job 对象本身，则被自动加上了这个 Label 对应的 Selector，从而 保证了 Job 与它所管理的 Pod 之间的匹配关系。

Job Controller 之所以要使用这种携带了 UID 的 Label，就是为了避免不同 Job 对象所管理的 Pod 发生重合。需要注意的是，这种自动生成的 Label 对用户来说并不友好，所以不太适合推广到 Deployment 等长作业编排对象上。



几分钟后再查看 Pod 状态，发现这个 Pod 处于 `Completed`状态，这也是在 Pod 模板中定义 `restartPolicy=Never` 的原因：离线计算的 Pod 永远都不应该被重启，否则它们会再重新计算一遍。

```
$ kubectl get po
NAME       READY   STATUS        RESTARTS   AGE
pi-5b7vl   0/1     Completed     0          7m8s

$ kubectl logs pi-5b7vl
3.141592653589793238462643383279502884197169399375105820974944592307......
```

> `restartPolicy `在 Job 对象里只允许被设置为 `Never `和 `OnFailure`；而在Deployment 对象里，restartPolicy 则只允许被设置为 `Always`。



### 作业失败

如果离线作业失败了，根据不同的`restartPolicy`，会有不同的做法：

- `Never`：Job Controller 会不断地尝试创建一个新 Pod
- `OnFailure`：Job Controller 不会去尝试创建新的 Pod，而是会不断地尝试重启 Pod 里的容器

当然，这个尝试肯定不能无限进行下去。在 Job 对象的 `spec.backoffLimit` 字段里定义了重试次数为 4（即，`backoffLimit=4`），这个字段的默认值是 6。

**Job Controller 重新创建 Pod 的间隔是呈指数增加的**，即下一次重新创建 Pod的动作会分别发生在 10 s、20 s、40 s …后。



当一个 Job 的 Pod 运行结束后，它会进入 Completed 状态。但是，如果这个 Pod因为某种原因一直不肯结束呢？

在 Job 的 API 对象里，有一个 `spec.activeDeadlineSeconds` 字段可以设置最长运行时间，比如：

```
spec:
  backoffLimit: 5
  activeDeadlineSeconds: 100
```

一旦运行超过了 100 s，这个 Job 的所有 Pod 都会被终止。并且，在 Pod 的状态里可以看到终止的原因是 `reason: DeadlineExceeded`。



### 作业并行

在 Job 对象中，负责并行控制的参数有两个：
1. `spec.parallelism`，它定义的是一个 Job 在任意时间**最多可以启动多少个 Pod 同时运行**
2. `spec.completions`，它定义的是 Job 至少要完成的 Pod 数目，即 **Job 的最小完成数**

在上面的 `job.yaml` 文件的`spec`部分加入：

```
parallelism: 2
completions: 4
```

这样就指定了这个 Job 最大的并行数是 2，而最小的完成数是 4。

```
$ kubectl create -f job.yaml
job.batch/pi created

$ kubectl get job
NAME   COMPLETIONS   DURATION   AGE
pi     0/4           0s         0s

$ kubectl get po
NAME       READY   STATUS              RESTARTS   AGE
pi-6vzxp   0/1     ContainerCreating   0          1s
pi-hkd9f   0/1     ContainerCreating   0          1s

$ kubectl get po
NAME       READY   STATUS      RESTARTS   AGE
pi-6vzxp   0/1     Completed   0          50s
pi-hkd9f   0/1     Completed   0          50s
pi-ltvlf   0/1     Completed   0          45s
pi-mmwpg   0/1     Completed   0          45s
```



通过上面的现象可以发现 Job Crontroller 的原理：

首先，Job Controller 控制的对象，直接就是 Pod。

其次，Job Controller 在控制循环中进行的调谐（Reconcile）操作，是根据实际在 Running状态 Pod 的数目、已经成功退出的 Pod 的数目，以及 `parallelism`、`completions `参数的值共同计算出在这个周期里，应该创建或者删除的 Pod 数目，然后调用 Kubernetes API 来执行这个操作。

在上面的例子中，当 Job 一开始创建出来时，实际处于 Running 状态的 Pod 数目 =0，已经成功退出的 Pod 数目 =0，而用户定义的 completions， 也就是最终用户需要的 Pod 数目 =4。所以，在这个时刻，需要创建的 Pod 数目 = 最终需要的 Pod 数目 - 实际在 Running 状态 Pod 数目 - 已经成功退出的 Pod 数目 = 4 - 0 - 0= 4。也就是说，Job Controller 需要创建 4个 Pod 来纠正这个不一致状态。

可是，我们又定义了这个 Job 的 `parallelism=2`。也就是说，每次并发创建的 Pod个数不能超过 2 个。所以，Job Controller 会对前面的计算结果做一个修正，修正后的期望创建的 Pod 数目应该是：2 个。

这时候，Job Controller 就会并发地向 kube-apiserver 发起两个创建 Pod 的请求。

类似地，如果在这次调谐周期里，Job Controller 发现实际在 Running 状态的 Pod 数目，比 parallelism 还大，那么它就会删除一些 Pod，使两者相等。



### Job 的常见使用方法

#### 外部管理器 +Job 模板

把 Job 的 YAML 文件定义为一个“模板”，然后用一个外部工具控制这些“模板”来生成 Job。

```
apiVersion: batch/v1
kind: Job
metadata:
  name: process-item-$ITEM
  labels:
    jobgroup: jobexample
spec:
  template:
    metadata:
      name: jobexample
      labels:
        jobgroup: jobexample
    spec:
      containers:
      - name: c
        image: busybox
        command: ["sh", "-c", "echo Processing item $ITEM && sleep 5"]
      restartPolicy: Never
```

在这个 Job 的 YAML 里，定义了 `$ITEM` 这样的“变量”。在控制这种 Job 时，只要注意如下两个方面：
1. 创建 Job 时，替换掉 `$ITEM` 这样的变量
2. 所有来自于同一个模板的 Job，都有一个` jobgroup: jobexample` 标签，即这一组 Job 使用这样一个相同的标识

这个过程如下：

```
$ mkdir ./jobs
$ for i in apple banana cherry
do
 cat job-tmpl.yaml | sed "s/\$ITEM/$i/" > ./jobs/job-$i.yaml
done

$ kubectl create -f ./jobs
$ kubectl get pods -l jobgroup=jobexample
NAME 					READY 		STATUS 		RESTARTS 	AGE
process-item-apple-kixwv 	0/1 	Completed 		0 		  4m
process-item-banana-wrsf7 	0/1 	Completed 		0 		  4m
process-item-cherry-dnfu9 	0/1 	Completed 		0 		  4m
```

在这种模式下使用 Job 对象，`completions `和 `parallelism `这两个字段都应该使用默认值 1，而不应该由我们自行设置。而作业 Pod 的并行控制，应该完全交由外部工具来进行管理。



#### 固定任务数目

只关心最后是否有指定数目（`spec.completions`）个任务成功退出。至于执行时的并行度是多少，并不关心。

在`spec.completions`  中指定要完成的任务数量， 至于`spec.parallelism` 可以设置，也可以不设置（默认为1）。

除了这种方法，还可以使用一个工作队列（Work Queue）进行任务分发：

```
apiVersion: batch/v1
kind: Job
metadata:
  name: job-wq-1
spec:
  completions: 8
  parallelism: 2
  template:
    metadata:
      name: job-wq-1
    spec:
      containers:
      - name: c
        image: myrepo/job-wq-1
        env:
        - name: BROKER_URL
          value: amqp://guest:guest@rabbitmq-service:5672
        - name: QUEUE
          value: job1
      restartPolicy: OnFailure
```

在这个例子中，使用一个运行在 Kubernetes 里的 RabbitMQ 充当工作队列，然后在 Pod 模板里定义 `BROKER_URL`，来作为消费者。一旦用 `kubectl create` 创建了这个 Job，它就会以并发度为 2 的方式，每两个 Pod 一组，共创建出 8 个 Pod。每个 Pod 都会去连接 `BROKER_URL`，从 RabbitMQ 里读取任务，然后各自进行处理。Pod 里的执行逻辑如下：

```
queue := newQueue($BROKER_URL, $QUEUE)
task := queue.Pop()
process(task)
exit
```

每个 Pod 只需要将任务信息读取出来，处理完成，然后退出即可。而作为用户，我只关心最终一共有 8 个计算任务启动并且退出，只要这个目标达到，我就认为整个 Job 处理完成了。所以说，这种用法，对应的就是“任务总数固定”的场景。



#### 固定并行度

这种场景下，需要决定什么时候启动新 Pod，什么时候 Job 才算执行完成。因为任务的总数是未知的，所以不仅需要一个工作队列来负责任务分发，还需要能够判断工作队列已经为空（即：所有的工作已经结束了）。

Job 的定义跟 固定任务数的定义相比，不需要定义`completions` 字段，其他没变化。而Pod 的逻辑就会稍微复杂些：

```
for !queue.IsEmpty($BROKER_URL, $QUEUE) {
  task := queue.Pop()
  process(task)
}
print("Queue empty, exiting")
exit
```

由于任务数目的总数不固定，所以每一个 Pod 必须能够知道，自己什么时候可以退出。在这个例子中，简单地以“队列为空”，作为任务全部完成的标志。所以说，这种用法，对应的是“任务总数不固定”的场景。

不过，在实际的应用中，需要处理的条件往往会非常复杂。比如，任务完成后的输出、每个任务 Pod 之间是不是有资源的竞争和协同等等。



## CronJob

CronJob 描述的，正是定时任务：

```
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  name: hello
spec:
  schedule: "*/1 * * * *"
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: hello
            image: busybox
            args:
            - /bin/sh
            - -c
            - date; echo Hello from the Kubernetes cluster
          restartPolicy: OnFailure
```

这个 YAML 文件中，最重要的关键词就是`jobTemplate`，可以发现，CronJob 是一个 Job 对象的控制器。

CronJob 与 Job 的关系，正如同 Deployment 与 Pod 的关系一样。CronJob 是一个专门用来管理 Job 对象的控制器。只不过，它创建和删除 Job 的依据，是 `schedule `字段定义的、一个标准的Unix Cron格式的表达式。

> Cron 表达式中的五个部分分别代表：分钟、小时、日、月、星期。
>
> `*/1 * * * *` ：`*/1` 中的 `*`表示从 0 开始，`/ `表示“每”，1 表示偏移量。所以，它的意思就是：从 0 开始，每 1 分钟执行一次。



创建 CronJob，并查看其信息：

```
$ kubectl create -f cronjob.yaml
cronjob.batch/hello created

# 三分钟后执行
$ kubectl get jobs
NAME               COMPLETIONS   DURATION   AGE
hello-1594710720   1/1           5s         2m24s
hello-1594710780   1/1           4s         84s
hello-1594710840   1/1           5s         23s

# 可以看到上一次执行的时间
$ kubectl get cronjob hello
NAME    SCHEDULE      SUSPEND   ACTIVE   LAST SCHEDULE   AGE
hello   */1 * * * *   False     0        52s             3m34s

# 默认最多保存最近的3个 Job
$ kubectl get jobs
NAME               COMPLETIONS   DURATION   AGE
hello-1594711260   1/1           3s         2m57s
hello-1594711320   1/1           5s         116s
hello-1594711380   1/1           3s         56s

$ kubectl get po
NAME                     READY   STATUS      RESTARTS   AGE
hello-1594711260-6jb9c   0/1     Completed   0          2m24s
hello-1594711320-2l4lv   0/1     Completed   0          83s
hello-1594711380-kxn56   0/1     Completed   0          23s

$ kubectl logs hello-1594711320-2l4lv
Tue Jul 14 07:22:10 UTC 2020
Hello from the Kubernetes cluster
```



由于定时任务的特殊性，很可能某个 Job 还没有执行完，另外一个新 Job 就产生了。这时候，可以通过 ` spec.concurrencyPolicy`字段来定义具体的处理策略。比如：
1. `concurrencyPolicy=Allow`：**默认情况**，意味着这些 Job 可以同时存在
2. `concurrencyPolicy=Forbid`：不会创建新的 Pod，该创建周期被跳过
3. `concurrencyPolicy=Replace`：新产生的 Job 会替换旧的、没有执行完的 Job

如果某一次 Job 创建失败，这次创建就会被标记为“miss”。当在指定的时间窗口内，miss的数目达到 100 时，那么 CronJob 会停止再创建这个 Job。

这个时间窗口，可以由 `spec.startingDeadlineSeconds` 字段指定。比如`startingDeadlineSeconds=200`，意味着在过去 200 s 里，如果 miss 的数目达到了 100 次，那么这个 Job 就不会被创建执行了。

